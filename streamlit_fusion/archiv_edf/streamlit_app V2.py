import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import streamlit as st

import pandas as pd
import io

# fichier des avis WebScraps de la Redoute
df = pd.read_csv("redoute.csv", sep=";")


# Titre principal
st.title("Customers Reviews Analytics")

# Barre lat√©rale avec le sommaire
st.sidebar.title("Sommaire")
pages = [
    "Introduction",
    "Collecte des Donn√©es",
    "Exploration et Analyse des Donn√©es",
    "Pr√©diction du Rating",
    "Analyse de Sentiment",
    "Topic Modeling",
    "Pr√©diction de la R√©ponse Fournisseur",
    "D√©mo",
    "Conclusion et Perspectives",
]

# S√©lection de la page dans la barre lat√©rale
page = st.sidebar.radio("Aller vers", pages)

# Contenu de chaque page
if page == pages[0]:
    st.write("## Introduction")

    st.write("#### Objectifs du Projet")
    st.markdown("- Pr√©dire les notations des clients")
    st.markdown("- Cat√©goriser les commentaires")
    st.markdown("- Proposer des r√©ponses automatiques")
    st.markdown("- Analyser les sentiments")

    st.write("#### Equipe Projet")
    st.text(
        """
        xxx
        xxx
        xxx
        """
    )

if page == pages[1]:
    st.write("## Collecte des Donn√©es")
    st.markdown("- Source de donn√©es: TrustedShops")
    st.markdown("- Entreprise cibl√©e : La Redoute")
    st.markdown("- WebScraping avec BeautifulSoup")
    st.markdown("- Donn√©es pour l'analyse exploratoire")

if page == pages[2]:
    st.write("## Exploration et Analyse des Donn√©es")
    st.markdown("- xx")
    st.markdown("- xx")
    st.markdown("- xx")

if page == pages[3]:
    st.write("## Pr√©diction du Rating en Fonction des Commentaires")
    st.write("#### Probl√©matique")
    # poser la probl√©matique

    st.write("#### D√©marche")
    # Mod√©lisation de base avec 3 variables explicatives
    # Bag of Words
    # GRU
    st.write("#### Mod√©lisation de Base")
    # Mod√©lisation de base avec 3 variables explicatives

    st.write("#### Bag of Words")
    # BoW , Tfidf , Cvtz ...

    st.write("#### GRU")
    # BoW , Tfidf , Cvtz ...

    st.write("#### R√©sultats")

if page == pages[4]:
    st.write("## Analyse de Sentiment")
    st.write(
        "Il est important -  avant de conduire ce type d‚Äôanalyse - **de pr√©parer le texte** afin qu‚Äôil soit le plus exploitable possible aux diff√©rents outils disponibles."
    )
    st.write(
        "On parle de pre-processing notamment en utilisant des techniques de **racinisation, tokenisation, utilisation d'expressions regulieres et suppression des stop words**."
    )

    import streamlit as st

# Titre
st.header("R√©sum√© de l'Analyse de Sentiments")

# Introduction
st.write(
    "On constate √† travers nos diverses it√©rations que l‚Äôanalyse de texte peut s‚Äôav√©rer ardue et reste  un processus tr√®s it√©ratif. Il en ressort aussi que certains outils vont tr√®s bien identifier la neutralit√© d‚Äôun commentaire mais par contre ne vont pas supporter une bonne pr√©diction de note.."
)

# Approches non supervis√©es
st.header("Approches non supervis√©es :")

# Word Cloud
st.subheader("Word Cloud :")
st.write(
    "Cr√©ation de 'Word Cloud' √† partir des commentaires pour visualiser les th√®mes dominants.  Il s‚Äôagit d‚Äôun **outil tr√®s pratique**, qui combin√© √† d‚Äôautres techniques comme la vectorisation peut se r√©v√©ler int√©ressant."
)

# Sentiment Analysis
st.subheader("Outils √† disposition :")
st.write(
    "L'analyse de sentiments couvre diverses m√©thodes, de la simple utilisation de lexiques √† des approches avanc√©es avec transformers. Nous avons utilis√© des outils tels que **Word Cloud, Text Blob, Vader, Naive Bayes et Bert**. **Multinomial Naive Bayes** est un algorithme de classification bay√©sienne na√Øve qui est adapt√© pour des donn√©es cat√©gorielles discr√®tes. **BERT**(Bidirectional Encoder Representations from Transformers) est un mod√®le de traitement du langage naturel bas√© sur des transformers, qui sont des mod√®les de r√©seaux de neurones particuli√®rement performants dans le traitement s√©quentiel de donn√©es."
)

# Exemple avec Vader
st.subheader("Prenons un exemple avec Vader :")
st.write(
    "VADER utilise un lexique pr√©-√©tiquet√© qui prend en compte la polarit√©, l'intensit√© et les √©motions li√©es aux mots sp√©cialement con√ßu pour g√©rer les nuances du langage naturel."
)
import pandas as pd
import matplotlib.pyplot as plt
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import matplotlib.pyplot as plt

# Chargement des donn√©es
df = pd.read_csv("redoute_v3.csv")

# T√©l√©chargement du lexique VADER pour l'analyse de sentiment
nltk.download("vader_lexicon")

# S√©lection d'un exemple de commentaire
comment = st.text_area(
    "Exemple:",
    "je commande depuis longtemps chez la redoute; j'y appr√©cie le choix , la rapidit√© de livraison et la facilit√© de r√®glement gr√¢ce √† la carte ,m√™me si presque  √† chaque fois je demandais un r√®glement comptant cela m'√©vitait de laisser mon num√©ro de carte bleue  sur le web ...par contre depuis quelques jours cela a chang√© je n'y comprends plus rien je ne peux plus payer comme √ßa alors que  je n'ai absolument  aucun d√©bit  en attente sur mon compte ....du coup par s√©curit√© face √† l'internet  j'ai d√ª r√©gler  mes deux derni√®res commandes avec une carte bancaire √† usage unique ce qui est un peu  plus compliqu√© pour moi et risque  forcement de me faire h√©siter pour des   futurs  achats sur ce site....dommage.",
)

# Initialisation de l'analyseur de sentiment VADER
sid = SentimentIntensityAnalyzer()

# Calcul du score de sentiment
sentiment_score = sid.polarity_scores(comment)

# Vader result on this specific example
x = [0.0, 0.977, 0.023, 0.4215]

st.set_option("deprecation.showPyplotGlobalUse", False)
plt.figure(figsize=(8, 6))
plt.pie(x, labels=["negative", "neutral", "positive", "coumpound"])
plt.title("Distribution of VADER Sentiment Scores")
plt.legend()
st.pyplot()

st.write(
    " Le resultat pour cet example exprime plus de **97% de neutralit√©**, en effet la lecture du texte r√©v√®le une tonalit√© mixte avec des aspects positifs et des pr√©occupations."
)


# Affichage du score de sentiment
# st.write("Score de sentiment :", sentiment_score)


# BERT
st.subheader("BERT:")
st.write(
    "L'utilisation de BERT pr√©-entra√Æn√© pour l'analyse de sentiment est puissante car il peut comprendre le contexte et les relations entre les mots de mani√®re plus sophistiqu√©e que les m√©thodes traditionnelles. Les resultats sont plus proches du rating client que Vader, am√©liorant la pr√©cision de l'√©valuation du sentiment."
)

# st.write(' ## Nous avons utilis√© plusieurs librairies dites pr√©-entra√Æn√©es telles que Vader, TextBlob, Bert')
# M√©canisme : Un texte ü°∫ un score de tonalit√© n√©gatif /positif
# PieChart : Distribution du score de sentiments
# Diagramme Barre => neutralit√© g√©n√©rale
# Graphique : Neutralit√© des r√©ponses fournisseurs
# Graphique : distribution rating versus Tonalit√©s sentiments

if page == pages[5]:
    st.write("## Topic Modeling")
    # objectifs : topics commentaires
    # D√©marche / LDA
    # R√©sultats
    st.write(
        """
**Objectifs :** Dans le but de satisfaire notre client et de faciliter la cat√©gorisation des commentaires clients et des r√©ponses, nous avons explor√© le topic modeling avec le mod√®le Latent Dirichlet Allocation de la librairie Gensim en Python.

**M√©thodologie :**
- D√©finition d‚Äôun corpus de mots : nos commentaires nettoy√©s et tokenis√©s, rassembl√©s en bag of words.
- Application du mod√®le LDA et cr√©ation d‚Äôun dictionnaire √©tablissant la correspondance entre les mots du corpus et les identifiants du mod√®le.

**R√©sultats :** L‚Äôanalyse LDA nous a permis d'identifier les sujets dominants pour chaque commentaire, r√©v√©lant des th√®mes li√©s √† la vente par correspondance, tels que les probl√®mes de livraison, de paiement, de conformit√© de taille, etc.
"""
    )

# Exemple de Sentiment Analysis Bert, combin√© au Topic modeling via un Chatbot

import pandas as pd
import numpy as np

from transformers import BertTokenizer, TFBertForSequenceClassification

from gensim import corpora, models

import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

# nltk.download("punkt")
# nltk.download("stopwords")


df = pd.read_csv("redoute_v3.csv")
df = df.head(20)

import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

# nltk.download("punkt")
# nltk.download("stopwords")

# word.isalpha() permet de filtrer que les caracteres, va enlever les chiffres, ponctuations et caracteres speciaux


# Fonction pour nettoyer le texte
def nettoyer_texte(comment):
    stop_words = set(stopwords.words("french"))
    ps = PorterStemmer()
    words = [
        ps.stem(word)
        for word in word_tokenize(comment.lower())
        if word.isalpha() and word not in stop_words
    ]
    return " ".join(words)


# Cr√©er une nouvelle colonne 'comment_cleaned' en appliquant la fonction nettoyer_texte
df["comment_cleaned"] = df["comment"].apply(nettoyer_texte)


# nettoyage supplementaire avec une regex qui prend uniquement les mots de 4 caracteres
from nltk.tokenize.regexp import RegexpTokenizer
import pandas as pd


def apply_regex(chaine):
    tokenizer = RegexpTokenizer("[a-zA-Z√©]{4,}")
    tokens_regex = tokenizer.tokenize(chaine)
    return " ".join(tokens_regex)  # pour rejoindre les tokens en une cha√Æne


# Appliquation de la fonction √† la colonne 'comment_cleaned'
df["comment_cleaned"] = df["comment_cleaned"].apply(apply_regex)


# Charger le mod√®le de sentiment BERT
model = TFBertForSequenceClassification.from_pretrained(
    "nlptown/bert-base-multilingual-uncased-sentiment"
)
tokenizer = BertTokenizer.from_pretrained(
    "nlptown/bert-base-multilingual-uncased-sentiment"
)


# Appliquer l'analyse de sentiment BERT √† la colonne 'comment_cleaned'
def predict_sentiment(comment):
    tokens = tokenizer.encode_plus(
        comment, return_tensors="tf", max_length=512, truncation=True
    )
    logits = model(tokens)["logits"]
    return np.argmax(logits.numpy())


df["sentiment_bert"] = df["comment_cleaned"].apply(predict_sentiment)


# Cr√©er le dictionnaire et le corpus bas√©s sur les commentaires nettoy√©s (bag of words)
dictionary = corpora.Dictionary(df["comment_cleaned"].apply(word_tokenize))
corpus = [
    dictionary.doc2bow(word_tokenize(comment)) for comment in df["comment_cleaned"]
]


def topic_modeling(comment, corpus, dictionary, num_topics=5):
    lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)
    topics = lda_model.print_topics(num_words=3)
    return topics


# Cr√©er le dictionnaire et le corpus bas√©s sur les commentaires nettoy√©s
# dictionary = corpora.Dictionary(df['comment_cleaned'].apply(word_tokenize))
# corpus = [dictionary.doc2bow(word_tokenize(comment)) for comment in df['comment_cleaned']]

# Cr√©er le mod√®le LDA
lda_model = models.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)

# Obtenir les termes les plus fr√©quents pour chaque topic - ici j'ai choisi 4 topics via topn
# on parcourt chaque topic du modele lda et on les stocke ds topic_terms
topic_terms = {}
for topic_id in range(lda_model.num_topics):
    terms = lda_model.show_topic(topic_id, topn=4)
    topic_terms[topic_id] = [term for term, _ in terms]


def get_dominant_topic(comment, lda_model, dictionary):
    # Utiliser le mod√®le LDA pour obtenir la distribution des topics
    bow_vector = dictionary.doc2bow(word_tokenize(comment))
    topics_distribution = lda_model.get_document_topics(bow_vector)

    # Trouver le topic dominant (num√©ro de topic) avec la probabilite la plus elevee
    # rappel : topics_distribution:  chaque √©l√©ment est un tuple de la forme (topic_id, probability)
    dominant_topic = max(topics_distribution, key=lambda x: x[1])[0]

    return dominant_topic


def get_topic_name(topic_id):
    # Obtenir les termes les plus fr√©quents du topic
    terms = topic_terms.get(topic_id, [])
    return ", ".join(terms)


# Titre de l'application - chatbot
st.subheader("Chatbot interactif avec Analyse de sentiment Bert et topic modeling")

# Section pour choisir un commentaire
selected_comment_index = st.number_input(
    "Saisissez l'index du commentaire :",
    min_value=0,
    max_value=len(df) - 1,
    value=0,
    step=1,
)

# Affichage du commentaire s√©lectionn√©
selected_comment = df.loc[selected_comment_index, "comment_cleaned"]
st.subheader("Commentaire s√©lectionn√© et nettoy√©:")
st.write(selected_comment)

# Analyse de sentiment avec BERT
sentiment_label = predict_sentiment(selected_comment)
st.subheader("Analyse de Sentiment BERT :")
st.write(f"Sentiment : {sentiment_label}")
st.write(
    "Pour rappel, l'√©chelle Bert du mod√®le choisi va de 0 a 4. 0 √©tant tr√®s n√©gatif et 4 tr√®s positif"
)

# Topic Modeling
dominant_topic = get_dominant_topic(selected_comment, lda_model, dictionary)
topic_name = get_topic_name(dominant_topic)
st.subheader("Topic Modeling :")
st.write(f"Topics dominants : {topic_name}")

# Rating client
rating = df.loc[selected_comment_index, "rating"]
st.subheader("Rating client :")
st.write(f"Rating client: {rating}")

print("---")

if page == pages[6]:
    st.write("## Pr√©diction de la R√©ponse Fournisseur")
    # objectifs
    # D√©marche
    # R√©sultats

if page == pages[7]:
    st.write("## D√©mo")
    # commentaires pos, neg, ambigu
    # pr√©diction du rating
    # pr√©diction du sentiment
    # pr√©diction du topic
    # pr√©diction r√©ponse fournisseur

if page == pages[8]:
    st.write("## Conclusion & Perspectives")
    st.header("Conclusion & Perspectives")
    # Conclusions
    # Perspectives
    # Introduction
    st.markdown(
        "Notre projet visait √† pr√©dire les notations des clients, cat√©goriser les commentaires, proposer des r√©ponses automatiques, et analyser les sentiments."
    )

    # Approche 1 : Mod√®les de classification
    st.subheader("Mod√®les de classification")
    st.markdown(
        "L‚Äôutilisation de divers mod√®les pour pr√©dire le sentiment client en se basant sur la longueur du commentaire, du titre, et la dur√©e depuis la transaction. **La r√©gression logistique simple a montr√© des performances notables**."
    )

    # Approche 2 : Bag of Words avec TF IDF et Count Vectorizer
    st.subheader("Bag of Words avec TF IDF et Count Vectorizer")
    st.markdown(
        "L'application du **Bag of Words avec TF IDF et Count Vectorizer** a permis **une bonne pr√©cision d‚Äôensemble**. Cependant, des limitations subsistent dans la pr√©cision de pr√©diction du sentiment n√©gatif."
    )

    # Approche 3 : R√©seaux de Neurones R√©currents GRU
    st.subheader("R√©seaux de Neurones R√©currents GRU")
    st.markdown(
        "**Les GRU ont surpass√© les mod√®les pr√©c√©dents, atteignant des pr√©cisions globales d√©passant 91%**, am√©liorant nettement la pr√©cision dans la pr√©diction du sentiment n√©gatif. Le r√©√©chantillonnage et la prise en compte du poids des classes pour les r√©seaux de neurones ont √©t√© essentiels pour √©quilibrer les donn√©es quel que soit le mod√®le."
    )

    # Pr√©diction du retour fournisseur
    st.subheader("Pr√©diction du retour fournisseur")
    st.markdown(
        "Une approche parall√®le a √©t√© adopt√©e, mettant l'accent sur le feature engineering, la recherche d'une trame standard, et le fine-tuning des mod√®les. L'analyse des commentaires fournisseur a r√©v√©l√© des **tendances sp√©cifiques** telles qu‚Äôune **standardisation des r√©ponses**, confirmant nos hypoth√®ses."
    )

    # Analyse des sentiments
    st.subheader("Analyse des sentiments")
    st.markdown(
        "Des word clouds √† BERT, les approches supervis√©es et semi-supervis√©es, notamment Bert et le Topic Modeling, ont fourni des informations tres tangibles."
    )

    # Chatbot interactif
    st.subheader("Chatbot interactif")
    st.markdown(
        "La mise en place d'un **Chatbot interactif**, int√©grant une √©valuation des sentiments et pr√©sentant les quatre principaux sujets sous-jacents, a rendu **conviviale l'analyse des commentaires**. Les r√©sultats concluants mettent en lumi√®re l'utilit√© de cet outil."
    )

    # Conclusion
    st.subheader("Conclusion")
    st.markdown(
        "En r√©sum√©, nos analyses approfondies nous ont permis d‚Äô√©laborer un bon syst√®me de pr√©dictions de l'√©valuation des commentaires, mais comme dans tout mod√®le de pr√©diction, des efforts continus sont n√©cessaires pour le perfectionner et optimiser les param√®tres. √Ä un stade avanc√©, une mod√©lisation de sujets plus pr√©cis pourrait diriger les commentaires vers les d√©partements sp√©cifiquement concern√©s."
    )
