import streamlit as st

import pandas as pd
import io

# fichier des avis WebScraps de la Redoute
df = pd.read_csv("redoute.csv", sep=";")


# Titre principal
st.title("Customers Reviews Analytics")

# Barre lat√©rale avec le sommaire
st.sidebar.title("Sommaire")
pages = [
    "Introduction",
    "Collecte des Donn√©es",
    "Exploration et Analyse des Donn√©es",
    "Pr√©diction du Rating",
    "Analyse de Sentiment",
    "Topic Modeling",
    "Pr√©diction de la R√©ponse Fournisseur",
    "D√©mo",
    "Conclusion et Perspectives",
]

# S√©lection de la page dans la barre lat√©rale
page = st.sidebar.radio("Aller vers", pages)

# Contenu de chaque page
if page == pages[0]:
    st.write("## Introduction")

    st.write("#### Objectifs du Projet")
    st.markdown("- Pr√©dire les notations des clients")
    st.markdown("- Cat√©goriser les commentaires")
    st.markdown("- Proposer des r√©ponses automatiques")
    st.markdown("- Analyser les sentiments")

    st.write("#### Equipe Projet")
    st.text(
        """
        xxx
        xxx
        xxx
        """
    )

if page == pages[1]:
    st.write("## Collecte des Donn√©es")
    st.markdown("- Source de donn√©es: TrustedShops")
    st.markdown("- Entreprise cibl√©e : La Redoute")
    st.markdown("- WebScraping avec BeautifulSoup")
    st.markdown("- Donn√©es pour l'analyse exploratoire")

if page == pages[2]:
    st.write("## Exploration et Analyse des Donn√©es")
    st.markdown("- xx")
    st.markdown("- xx")
    st.markdown("- xx")

if page == pages[3]:
    st.write("## Pr√©diction du Rating en Fonction des Commentaires")
    st.write("#### Probl√©matique")
    # poser la probl√©matique

    st.write("#### D√©marche")
    # Mod√©lisation de base avec 3 variables explicatives
    # Bag of Words
    # GRU
    st.write("#### Mod√©lisation de Base")
    # Mod√©lisation de base avec 3 variables explicatives

    st.write("#### Bag of Words")
    # BoW , Tfidf , Cvtz ...

    st.write("#### GRU")
    # BoW , Tfidf , Cvtz ...

    st.write("#### R√©sultats")

if page == pages[4]:
    st.write("## Analyse de Sentiment")
    # Librairies pr√©-entra√Æn√©es : Vader, TextBlob, Bert
    # M√©canisme : Un texte ü°∫ un score de tonalit√© n√©gatif /positif
    # PieChart : Distribution du score de sentiments
    # Diagramme Barre => neutralit√© g√©n√©rale
    # Graphique : Neutralit√© des r√©ponses fournisseurs
    # Graphique : distribution rating versus Tonalit√©s sentiments

if page == pages[5]:
    st.write("## Topic Modeling")
    # objectifs : topics commentaires
    # D√©marche / LDA
    # R√©sultats

if page == pages[6]:
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns
    

    st.write("## Pr√©diction de la R√©ponse Fournisseur")
    # Chargement des donn√©es
    st.write('### Visualisation du DataFrame')
    df = pd.read_csv('redoute_v31.csv')
    st.write(df.head())  # Affiche les premi√®res lignes du DataFrame

    st.write('### EDA (Exploration de donn√©es)')
    # 'createdAt' et 'SupplierReplyDate' 
    df['createdAt'] = pd.to_datetime(df['createdAt'])
    df['SupplierReplyDate'] = pd.to_datetime(df['SupplierReplyDate'])

    # Calculs n√©cessaires pour les graphiques
    df['Delay'] = (df['SupplierReplyDate'] - df['createdAt']).dt.days
    average_delay = df['Delay'].mean()
    ratings_per_month = df.groupby(df['createdAt'].dt.to_period("M"))['rating'].mean()
    supplier_replies_per_month = df.groupby(df['SupplierReplyDate'].dt.to_period("M")).size()

    # Choix de graphique dans la zone principale
    choix_graphique = st.selectbox(
    "S√©lectionnez le graphique √† afficher",
    ('Nombre de r√©ponses fournisseur par jour', 'Histogramme des d√©lais de r√©ponse', 'Analyse du d√©lai moyen par rating', '√âvaluation et r√©ponses fournisseur par mois' )
    )

    if choix_graphique == 'Nombre de r√©ponses fournisseur par jour':
        st.write("### Nombre total de r√©ponses fournisseur par jour")
        fig, ax = plt.subplots()
        df.groupby(df['createdAt'].dt.date).size().plot(kind='line', ax=ax)
        plt.ylabel('Nombre de r√©ponses')
        plt.xticks(rotation=45)
        st.pyplot(fig)

    elif choix_graphique == 'Histogramme des d√©lais de r√©ponse':
        st.write("### Histogramme des d√©lais de r√©ponse")
        fig, ax = plt.subplots()
        plt.hist(df['Delay'], bins=50, edgecolor="k", alpha=0.7)
        plt.axvline(average_delay, color='red', linestyle='dashed', linewidth=1, label=f'D√©lai moyen: {average_delay:.2f} jours')
        plt.title('Distribution des d√©lais de r√©ponse des fournisseurs')
        plt.xlabel('D√©lai (en jours)')
        plt.ylabel('Nombre de r√©ponses')
        plt.legend()
        st.pyplot(fig)

    elif choix_graphique == 'Analyse du d√©lai moyen par rating':
        st.write('### Analyse du d√©lai moyen par rating')
        
        grouped = df.groupby('rating')['Delay'].mean().reset_index()
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.bar(grouped['rating'], grouped['Delay'], color=['red', 'orange', 'yellow', 'green', 'blue'])
        ax.set_title('D√©lai moyen par Rating')
        ax.set_xlabel('Rating')
        ax.set_ylabel('D√©lai moyen (en jours)')
        ax.set_xticks(grouped['rating'])
        ax.grid(axis='y')
        st.pyplot(fig)

    elif choix_graphique == '√âvaluation et r√©ponses fournisseur par mois':
        st.write("### √âvaluation moyenne et nombre de r√©ponses fournisseur par mois")
        fig, ax1 = plt.subplots(figsize=(10, 6))

        color = 'tab:blue'
        ax1.set_xlabel('Mois')
        ax1.set_ylabel('√âvaluation moyenne', color=color)
        ax1.plot(ratings_per_month.index.astype('str'), ratings_per_month.values, color=color)
        ax1.tick_params(axis='y', labelcolor=color)

        ax2 = ax1.twinx()  

        color = 'tab:red'
        ax2.set_ylabel('Nombre de r√©ponses fournisseurs', color=color)  
        ax2.plot(supplier_replies_per_month.index.astype('str'), supplier_replies_per_month.values, color=color)
        ax2.tick_params(axis='y', labelcolor=color)

        fig.tight_layout()  
        plt.title('√âvaluation moyenne et nombre de r√©ponses fournisseurs par mois')
        st.pyplot(fig)

    import scikit_posthocs as sp
    import statsmodels.api as sm
    from scipy.stats import levene
    from statsmodels.formula.api import ols
    from scipy.stats import kruskal
    import streamlit as st
    import pandas as pd
    import numpy as np
    import scikit_posthocs as sp
    
    st.write("## Tests statistiques")
    df = pd.read_csv('redoute_v31.csv')

    option_test = st.selectbox(
    "Choisissez le test statistique √† effectuer :",
    ("Homog√©n√©it√© des variances (Test de Levene)", "Normalit√© des r√©sidus (QQ-plot)", "Test de Kruskal-Wallis")
    )
    
    # 1/ Homog√©n√©it√© des variances / Test de Levene
    if option_test == "Homog√©n√©it√© des variances (Test de Levene)":
        st.write("### 1. Test d'homog√©n√©it√© des variances (Test de Levene)")
    
        groups = [df['rating'][df['SupplierReply'] == reply] for reply in df['SupplierReply'].unique()]
        statistic, p_value = levene(*groups)
        st.write(f'Statistique de test: {statistic:.4f}')
        st.write(f'P-value: {p_value:.4g}')  # Affiche la p-value 

    # V√©rifie si la p-value est inf√©rieure √† votre alpha (par exemple, 0.05)
        if p_value < 0.05:
            st.write("Les variances ne sont pas √©gales selon le test de Levene.")
        else:
            st.write("Les variances sont √©gales selon le test de Levene.")
    
    # 2/ Normalit√© des r√©sidus
    elif option_test == "Normalit√© des r√©sidus (QQ-plot)":
        st.write("### 2. Normalit√© des r√©sidus (Graphiquement avec un QQ-plot)")
    
    # Mod√®le OLS pour les r√©sidus
        model = ols('rating ~ C(SupplierReply)', data=df).fit()
        residus = model.resid
    
    # QQ-plot
        fig = sm.qqplot(residus, fit=True, line="45")
        st.pyplot(fig)

    # Test de Kruskal-Wallis
    elif option_test == "Test de Kruskal-Wallis":
        st.write("### 3. Test de Kruskal-Wallis")

        groups = [group['rating'].values for name, group in df.groupby('SupplierReply')]
        stat, p_value = kruskal(*groups)

        st.write(f'Statistique de test: {stat}')
        st.write(f'P-value: {p_value}')

        alpha = 0.05
        if p_value < alpha:
            st.write("On rejette l'hypoth√®se nulle : il existe des diff√©rences significatives entre les groupes.")
        else:
            st.write("On ne peut pas rejeter l'hypoth√®se nulle : il n'y a pas de preuve de diff√©rences significatives entre les groupes.")

    # Fonction mise en cache
    @st.cache_data
    def calculer_test_dunn(notes, categories, methode):
        return sp.posthoc_dunn([notes[categories == k] for k in np.unique(categories)], p_adjust=methode)

    # Chargement des donn√©es
    df = pd.read_csv('redoute_v31.csv')
    notes = df['rating'].values
    categories = df['SupplierReply'].values

    # Titre 
    st.write("## 4. Tests de Dunn avec diff√©rents ajustements")

    # S√©lection de la m√©thode d'ajustement
    option_ajustement = st.selectbox(
    "Choisissez la m√©thode d'ajustement pour le test de Dunn :",
    ("bonferroni", "holm", "fdr_bh")
    )

    

    # Calcul et affichage des r√©sultats
    if st.button("Effectuer le test de Dunn", key="unique_key_dunn_test"):
        p_values = calculer_test_dunn(notes, categories, option_ajustement)
        st.write(f"R√©sultats du test de Dunn avec ajustement {option_ajustement}:")

        # Cr√©ation de la heatmap de toutes les p-valeurs
        mask = np.triu(np.ones_like(p_values, dtype=bool))
        plt.figure(figsize=(10, 8))
        sns.heatmap(p_values, mask=mask, cmap='viridis', vmax=0.05)
        plt.title('Heatmap des p-valeurs ajust√©es')
        st.pyplot(plt)

        # Heatmap des comparaisons significatives
        alpha = 0.05
        significant_comparisons = p_values.where(p_values <= alpha)
        significant_mask = mask & (p_values <= alpha)
    
        plt.figure(figsize=(10, 8))
        sns.heatmap(significant_comparisons, mask=significant_mask, cmap='viridis', vmax=0.05, annot=True)
        plt.title('Comparaisons significatives (p <= 0.05)')
        st.pyplot(plt)

        # Affichage des paires significatives
        paires_significatives = np.where(p_values <= alpha)
        paires_indices = list(zip(paires_significatives[0], paires_significatives[1]))

    

    import streamlit as st
    import pandas as pd
    import joblib
    import re
    import nltk
    from nltk.corpus import stopwords
    from nltk.tokenize import word_tokenize
    from nltk.sentiment import SentimentIntensityAnalyzer
    from sklearn.model_selection import train_test_split
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.linear_model import LogisticRegression
    from sklearn.metrics import accuracy_score

    nltk.download('punkt')
    nltk.download('stopwords')
    nltk.download('wordnet')
    nltk.download('vader_lexicon')

# Chargement et pr√©paration des donn√©es
    @st.cache_data
    def charger_donnees(file):
        return pd.read_csv(file, sep=",")

    @st.cache_data
    def preprocess_text(text):
    # Cr√©ation du stemmer √† l'int√©rieur de la fonction
        stemmer = nltk.SnowballStemmer("french")
        text = text.lower()
        text = re.sub(r'http\S+', '', text)
        text = re.sub(r'bonjour,','', text)
        text = re.sub(r'[\w\.-]+ de l\'√©quipe service client', '', text)
        text = re.sub(r'[^\w\s]', '', text)
        text = re.sub(r'\d+', '', text)
        tokens = word_tokenize(text)
        tokens = [word for word in tokens if word not in stopwords.words('french')]
        tokens = [stemmer.stem(word) for word in tokens]
        return ' '.join(tokens)

    @st.cache_data
    def entrainer_modele_naif(_X_train, _y_train):
        model = LogisticRegression(max_iter=1000)
        model.fit(_X_train, _y_train)
        return model

    @st.cache_data
    def analyser_sentiments(text):
        sia = SentimentIntensityAnalyzer()
        return sia.polarity_scores(text)

    # Chargez les donn√©es
    df = charger_donnees('redoute_v31.csv')

    # Streamlit UI
    st.title("Analyse de Sentiments et Mod√©lisation")

    # Mod√©lisation Na√Øve
    st.header("Mod√©lisation Na√Øve")
    df['processed_comments'] = df['SupplierReply'].apply(preprocess_text)
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(df['processed_comments'])
    y = df['rating'].values
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model_naif = entrainer_modele_naif(X_train, y_train)
    y_pred = model_naif.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    st.write(f"Pr√©cision du mod√®le na√Øf: {accuracy:.2f}")
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(df['processed_comments'])
    joblib.dump(vectorizer, 'vectorizer.joblib')
    

    # Mod√®le VADER
    st.header("Mod√®le VADER")
    df['sentiment_scores'] = df['SupplierReply'].apply(lambda x: analyser_sentiments(x)['compound'])
    df[['id','SupplierReply', 'sentiment_scores']].to_csv('sentiments_vader.csv', index=False)
    st.write("Les mod√®les ont √©t√© entra√Æn√©s et sauvegard√©s pour la d√©monstration.")

if page == pages[7]:
    import streamlit as st
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns
    import nltk
    from nltk.sentiment import SentimentIntensityAnalyzer
    from sklearn.model_selection import train_test_split
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.linear_model import LogisticRegression
    from sklearn.metrics import accuracy_score
    import re
    import joblib
    from nltk.stem.snowball import SnowballStemmer
    from utils import preprocess_text
    from utils import analyser_sentiments

    st.write("## D√©mo")
    # commentaires pos, neg, ambigu
    # pr√©diction du rating
    # pr√©diction du sentiment
    # pr√©diction du topic
    # pr√©diction r√©ponse fournisseur
    st.title("D√©monstration des Mod√®les")

    # Chargement du mod√®le pr√©-entra√Æn√© et du vectoriseur
    model_naif = joblib.load('modele_naif.joblib')
      
    

    # Assurez-vous que le chemin est correct et que 'vectorizer.joblib' existe dans ce chemin
    vectorizer = joblib.load('vectorizer.joblib')
    # Option pour s√©lectionner le mod√®le √† d√©montrer
    modele_option = st.selectbox("Choisir le mod√®le √† d√©montrer:", ["Mod√®le Na√Øf", "Mod√®le VADER"])

    if modele_option == "Mod√®le Na√Øf":
        # UI pour entr√©e utilisateur pour le mod√®le Na√Øf
        user_input = st.text_area("Entrez un texte pour classification par le mod√®le Na√Øf:", "Ce produit est excellent !")
        if st.button("Classer avec le mod√®le Na√Øf"):
            processed_input = preprocess_text(user_input)  
            prediction = model_naif.predict(vectorizer.transform([processed_input]))
            st.write(f"Pr√©diction de la classe : {prediction[0]}")
 

    elif modele_option == "Mod√®le VADER":
        df_sentiments = pd.read_csv('sentiments_vader.csv')
        user_selection = st.radio("Choisir un exemple ou entrer un nouveau texte pour VADER", ['Choisir un exemple', 'Entrer un texte'])

        if user_selection == 'Choisir un exemple':
            example_id = st.selectbox("Choisir un ID de commentaire pour VADER:", df_sentiments['id'].values)
            selected_comment = df_sentiments.loc[df_sentiments['id'] == example_id, 'SupplierReply'].iloc[0]
            st.write(f"Commentaire pour l'ID {example_id}: {selected_comment}")
            selected_score = df_sentiments.loc[df_sentiments['id'] == example_id, 'sentiment_scores'].iloc[0]
            st.write(f"Scores de sentiment pour l'ID {example_id}: {selected_score}")
        else:
            user_input = st.text_area("Entrez un texte pour analyse de sentiment par VADER:", "Ce produit est excellent !")
            if st.button("Analyser Sentiment avec VADER"):
                sentiment_scores = analyser_sentiments(user_input)
                st.write(sentiment_scores)
    

if page == pages[8]:
    st.write("## Conclusion & Perspectives")
    # Conclusions
    # Perspectives
