import streamlit as st
import pandas as pd
import numpy as np
import io
import plotly.express as px
import tensorflow as tf
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import nltk
from nltk.tokenize.regexp import RegexpTokenizer
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# nltk.download("punkt")
# nltk.download("stopwords")

from transformers import BertTokenizer, TFBertForSequenceClassification

from gensim import corpora, models


#  fonction pour charger des fichers csv
@st.cache_data  # pour r√©duire le temps de chargement du dataframe
def load_data(file_name, sep=","):
    return pd.read_csv(file_name, sep=sep, index_col=0)


# Titre principal
st.title(":blue[Customers Reviews Analytics]")

# Barre lat√©rale avec le sommaire
st.sidebar.title(":blue[Sommaire]")
pages = [
    "Introduction",
    "Collecte des Donn√©es",
    "Exploration et Analyse des Donn√©es",
    "Pr√©diction supervis√©e du sentiment",
    "Analyse de Sentiment",
    "Topic Modeling",
    "Pr√©diction de la R√©ponse Fournisseur",
    "D√©mo",
    "Conclusion et Perspectives",
]

# S√©lection de la page dans la barre lat√©rale
page = st.sidebar.radio("Aller vers", pages)

# Contenu de chaque page
if page == pages[0]:
    st.write("## Objectifs du Projet")
    st.markdown("###### - Collecter des avis clients sur des plateformes en ligne")
    st.markdown("###### - Pr√©dire la statisfaction client")
    st.markdown("###### - Cat√©goriser les commentaires clients")
    st.markdown("###### - Proposer des r√©ponses automatiques aux commentaires")
    st.markdown("###### - Analyser le sentiment des avis des clients")

    st.write("## Equipe Projet")
    st.text(
        """
        Michel Douglas Piamou
        Mike Boudhabhay
        Edwige F√®ve
        """
    )

if page == pages[1]:
    st.write("## Collecte des Donn√©es")
    st.divider()
    # Source de donn√©es
    col1, col2 = st.columns(2)
    with col1:
        st.write("##### Source de donn√©es")
    with col2:
        st.markdown(
            """ **TrustedShops**, Entreprise allemande qui propose entre autres:
                        Certification de sites web marchands, 
                        Services **d'√©valuation et d'avis clients**
                    """,
            unsafe_allow_html=True,
        )
    st.divider()
    # Entreprise cible
    col3, col4 = st.columns(2)
    with col3:
        st.markdown("##### Entreprise cibl√©e")
    with col4:
        st.markdown(
            "**La Redoute**, Leader fran√ßais du e-commerce en mode et maison",
            unsafe_allow_html=True,
        )
    st.divider()
    col5, col6 = st.columns(2)
    with col5:
        st.markdown(
            "##### WebScraping des donn√©es des avis clients", unsafe_allow_html=True
        )
    with col6:
        st.markdown(
            "1 - **requests.get + BeautifulSoup + Pandas**",
            unsafe_allow_html=True,
        )
        st.markdown(
            "2 - 1er nettoyage et formatage des donn√©es, puis stockage dans un fichier .csv",
            unsafe_allow_html=True,
        )
    st.divider()
    st.markdown("##### Donn√©es pour l'Analyse Exploratoire", unsafe_allow_html=True)
    df = load_data("redoute.csv", sep=";")
    st.dataframe(df.head(5))
    # pour afficher df.info()
    buffer = io.StringIO()
    df.info(buf=buffer)
    s = buffer.getvalue()
    st.text(s)

if page == pages[2]:
    # chargement des donn√©es
    df = load_data("redoute_v3.csv")
    # selection des colonnes utiles
    cols = [
        "rating",
        "comment_length",
        "log_comment_length",
        "title_length",
        "nb_days_before_review",
        "month_of_cmt",
        "day_of_cmt",
        "weekday_of_cmt",
        "cmt_in_weekend",
        "hour_of_cmt",
    ]
    df = df[cols]

    st.write("## Exploration et Analyse des Donn√©es")
    st.divider()
    st.markdown(" ##### Traitement des valeurs manquantes")
    st.divider()
    st.markdown(" ##### Enrichissement du jeu de donn√©es")
    st.text(
        "- Mois, jours ouvr√©s/week-end, heures auxquels les commentaires ont √©t√© post√©s"
    )
    st.text("- Longeur du commentaire")
    st.text(" - Logarithme de la longeur du commentaire")
    st.text("- Longueur du titre du commentaire")
    st.text(
        "- Nombre de jours entre la date de transaction et la date de cr√©ation du commentaire "
    )
    st.divider()
    st.markdown("##### Analyse des distributions")

    # Distribution du rating selon la date/temps choisi de l'utilisateur
    options = [
        "",
        "month_of_cmt",
        "weekday_of_cmt",
        "cmt_in_weekend",
        "hour_of_cmt",
    ]
    # menu de s√©lection des variable pour le Box plot
    var_selected = st.selectbox(
        "###### Afficher le distribution du rating selon le temps/date de votre choix",
        options,
    )
    # Box plot de la longeur des commentaires vs rating
    if var_selected == "":
        fig = plt.figure(figsize=(3, 3))
        sns.countplot(data=df, x="rating", palette="pastel")
        plt.title("R√©partition du rating")
    else:
        fig = plt.figure(figsize=(3, 3))
        sns.countplot(data=df, x="rating", hue=var_selected, palette="pastel")
        plt.title("Distribution du rating vs " + var_selected)
    st.pyplot(fig)

    # Affichage du BOXPLOT des variables explicatives

    # Choix d'une variable pour afficher le boxplot
    options = [
        "comment_length",
        "log_comment_length",
        "title_length",
        "nb_days_before_review",
    ]

    # menu de s√©lection des variable pour le Box plot
    var_selected = st.selectbox(
        "###### S√©lectionnez une variable pour afficher sa distribution", options
    )

    # Box plot de la longeur des commentaires vs rating
    fig = plt.figure(figsize=(2, 3))
    sns.boxplot(
        data=df, x="rating", y=var_selected, hue="rating", palette="Set2", legend=False
    )
    plt.title("Box plot - " + var_selected)
    st.pyplot(fig)

    # Affichage heatmap des corr√©lations
    st.divider()
    st.markdown(" ##### Analyse des corr√©lations")
    fig = plt.figure(figsize=(7, 7))
    sns.heatmap(df.corr(), annot=True, fmt=".2f")
    st.pyplot(fig)
    st.divider()
    st.markdown("##### Test statistiques ")
    st.text("- test ANOVA : rating versus log_comment_length")
    st.text(
        " - test de Kruska Wallis : effet du rating sur les  variables explicatives"
    )
    st.text(" - test de spearman : corr√©lations entre variables explicatives")

    st.divider()

    st.markdown(
        "##### Mesure de la colin√©arit√© entre variables explicatives : calcul du VIF"
    )


if page == pages[3]:
    # Chargement des donn√©es des performances
    df_perf_bin = load_data("data_perf.csv")

    # graphique radar des m√©triques d'une liste de mod√®les pour clf binaire
    def plot_radar(data, model_list, best_model):
        metrics = data.index.to_list()
        fig = go.Figure()
        for model in models_list:
            fig.add_trace(
                go.Scatterpolar(
                    r=data[model].to_list(),
                    theta=metrics,
                    # fill='toself',
                    name=model,
                )
            )
        fig.update_layout(
            title="M√©triques : " + model_selected + " vs " + best_model,
            polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
            width=600,
            height=600,
            showlegend=True,
        )
        st.plotly_chart(fig, use_container_width=True)

    st.write("## Pr√©diction supervis√©e du sentiment")

    st.divider()
    st.write("### Classification Binaire")
    st.latex(
        r"sentiment = \begin{cases} 0 & \text{si } rating \leq 3 \\ 1 & \text{si } rating \geq 4 \end{cases}"
    )
    st.divider()
    st.write("### Classification Multi-classes")
    st.latex(
        r"sentiment = \begin{cases} -1 & \text{si } rating < 3 \\ 0 & \text{si } rating = 3 \\1 & \text{si } rating > 3 \end{cases}"
    )

    st.divider()
    st.write("### D√©marche")
    st.markdown(
        "- Une mod√©lisation na√Øve dite Baseline, Approche Bag of Words, Deep Learning"
    )
    st.markdown(
        "- **Sous-√©chantillonage al√©atoire** ou utilisation du poids des classes pour prendre en compte le d√©s√©quilibre des classes"
    )

    st.markdown("- M√©triques prinicipales de comparaison des mod√®les :")
    st.text("Accuracy, Precision du sentiment n√©gatif, Rappel du sentiment n√©gatif")
    st.text("F1-macro, Rappel-macro,  Precision-macro")
    st.text("matrices de confusion")

    st.markdown("- Recherche de meilleurs  hyperparm√®tres avec GridSearchCV")

    st.divider()
    st.write("### 1. Mod√©lisation de Base")
    st.image("st_process_bsl_modeling.jpg")
    st.markdown("Pr√©diction du sentiment √† partir de 3 variables explicatives")

    # M√©triques des mod√®les baseline
    # Options de choix des mod√®les baseline
    options = [
        "dec_tree_bsl",
        "r_fo_bsl",
        "g_nb_bsl",
        "m_nb_bsl",
        "c_nb_bsl",
        "lsvc_bsl",
        "svc_bsl",
        "knn_bsl",
        "gdb_bsl",
        "grid_log_reg_bsl_grid",
        "grid_lsvc_bsl_grid",
        "grid_svc_bsl_grid",
        "grid_gdb_bsl_grid",
    ]
    # menu de s√©lection des variable pour le Box plot
    model_selected = st.selectbox(
        "###### S√©lectionnez un mod√®le baseline pour afficher ses m√©triques", options
    )
    # Radar des m√©triques du mod√®le choix versus regression logistique (log_reg_bsl)
    models_list = ["log_reg_bsl", model_selected]
    data = df_perf_bin.iloc[:, :-2].set_index("model").T
    plot_radar(data, models_list, "log_reg_bsl")

    st.divider()
    st.write("### 2. Bag of Words")
    st.image("st_process_bag_of_word.jpg")

    st.markdown("Chaque commentaire est transform√© en un **vecteur num√©rique**")
    st.markdown(
        """**Count Vectorization**: compter le nombre d'occurrences des termes dans le commentaire"""
    )
    st.markdown(
        """**Pond√©ration TF-IDF** tient compte de la fr√©quence du terme dans le commentaire (TF) et de 
        l'inverse de la fr√©quence du terme dans l'ensemble des commentaires (IDF)"""
    )

    # menu de s√©lection des mod√®les pour comparaison des m√©triques
    options_bow = df_perf_bin[df_perf_bin["model_cat"].isin(["tfidf", "cvtz"])][
        "model"
    ].to_list()
    options_bow.remove("Logistic_reg_cvz")
    model_selected = st.selectbox(
        "###### S√©lectionnez un mod√®le pour afficher ses m√©triques", options_bow
    )
    # Radar des m√©triques du mod√®le choix versus regression logistique (log_reg_bsl)
    models_list = ["Logistic_reg_cvz", model_selected]
    data = df_perf_bin.iloc[:, :-2].set_index("model").T
    plot_radar(data, models_list, "Logistic_reg_cvz")

    # R√©seau de neuronnes Gates Recurrent Units
    # wordcloud pour d√©finition RNN
    from wordcloud import WordCloud
    import matplotlib.pyplot as plt

    # Liste de mots cl√©s repr√©sentatifs d'un RNN
    rnn_keywords = [
        "sequence",
        "recurrent",
        "neural network",
        "context",
        "LSTM",
        "GRU",
        "backpropagation",
        "embedding",
        "prediction",
        "generation",
        "time series",
        "memory",
        "hidden state",
        "long short-term memory",
        "contextual",
        "sequential",
        "understanding",
        "language model",
        "dependency",
        "stateful",
    ]
    # nuage de mots avec les mots cl√©s RNN
    wordcloud = WordCloud(width=800, height=400, background_color="white").generate(
        " ".join(rnn_keywords)
    )

    st.divider()
    st.write("### 3. R√©seau de Neurones")
    st.image("st_process_neural_network.jpg")

    st.divider()
    st.markdown("#### R√©seau de neurones r√©currents")
    st.image(wordcloud.to_array(), caption="Nuage de mots repr√©sentatif d'un RNN")

    st.divider()
    st.markdown("#### GRU - Gated Recurrent Units")
    st.markdown(
        """ - Variante des r√©seaux de neurones r√©currents qui permettent de capturer 
        les d√©pendances √† long terme dans les s√©quences de donn√©es."""
    )
    st.markdown(
        """ - Alternative au RNN tradidionnel pour palier au probl√®me de disparition du gradient"""
    )

    col1, col2 = st.columns(2)
    with col1:
        st.markdown("##### Architecture d'une cellule d'un GRU :")
        st.markdown("- une porte de r√©initialisation (Reset Gate)")
        st.markdown("- une porte d'oubli (Update Gate)")
    with col2:
        st.image("st_gru_cell.jpg")

    # code du mod√®le GRU_1
    st.markdown("##### Exemple de mod√®le GRU mis en oeuvre:")
    code_python_GRU = """
        embedding_size = 100
        model = Sequential()
        model.add(Embedding(input_dim=num_words, 
                            output_dim=embedding_size, 
                            input_length=max_tokens,
                            name="embedding_layer"))
        model.add(GRU(units=128, return_sequences=True))
        model.add(GRU(units=64, return_sequences=True)) 
        model.add(GRU(units=12))
        model.add(Dense(1, activation='sigmoid'))
        # Compile
        optimizer = Adam(learning_rate=0.008)
        model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])
    """
    st.code(code_python_GRU, language="python")

    # ---------------------------------------
    # menu de s√©lection des mod√®les pour comparaison des m√©triques
    options_dl = df_perf_bin[df_perf_bin["model_cat"].isin(["GRU", "LSTM"])][
        "model"
    ].to_list()
    options_dl.remove("GRU_1")
    model_selected = st.selectbox(
        "###### S√©lectionnez un mod√®le pour afficher ses m√©triques", options_dl
    )
    # Radar des m√©triques du mod√®le choix versus mod√®le GRU_1
    models_list = ["GRU_1", model_selected]
    data = df_perf_bin.iloc[:, :-2].set_index("model").T
    plot_radar(data, models_list, "GRU_1")

    # -----------------------------------

    st.write("### R√©sultats compar√©s - Classification Binaire")

    # Accuracy des mod√®les
    col_metrics = [
        "model",
        "accuracy",
        "recall_0",
        "precision_0",
        "recall_macro",
        "precision_macro",
    ]
    top_models = [
        "log_reg_bsl",
        "Logistic_reg_cvz",
        "SVC(kernel=rbf)_tfidf",
        "GRU_esz50_1",
        "GRU_1",
    ]

    # 1. Precision et Recall du Sentiment N√©gatif
    fig = px.scatter(
        df_perf_bin,
        x="recall_0",
        y="precision_0",
        size="size",
        color="model_cat",
        hover_name="model",
        hover_data=["model", "accuracy"],
        log_x=False,
        size_max=25,
        title="Pr√©cision et Recall du sentiment n√©gatif",
    )
    fig.add_hline(y=0.5, line_dash="dash", line_color="red")
    st.plotly_chart(fig, use_container_width=True)

    # 2. Accuracy vs Rappel du sentiment N√©gatif
    fig = px.scatter(
        df_perf_bin,
        # x="precision_0",
        x="accuracy",
        y="accuracy",
        size="size",
        color="model_cat",
        hover_name="model",
        hover_data=["model", "accuracy"],
        log_x=False,
        size_max=25,
        title="Accuracy d'ensemble",
    )
    fig.add_hline(y=0.5, line_dash="dash", line_color="red")
    st.plotly_chart(fig, use_container_width=True)

    # 3. Scatter plot de comparaison des performances
    data = df_perf_bin[col_metrics]
    data = data[data["model"].isin(top_models)].set_index("model")
    fig2 = px.line(
        data.T, markers=True, title="M√©triques pour une s√©lection de mod√®les"
    )
    fig2.update_yaxes(tick0=0, dtick=0.1)
    fig2.add_hline(y=0.5, line_dash="dash", line_color="red")
    st.plotly_chart(fig2, use_container_width=True)

    st.write("### R√©sultats compar√©s - Classification Multi-Classe")
    # donn√©es performance sur multi-classes
    df_perf_mcl = load_data("data_mcl_perf.csv")

    # m√©trique utilis√©e
    metrics = ["model", "accuracy", "f1_macro", "recall_macro", "precision_macro"]
    models_list = [
        "log_reg_bsl",
        "lsvc_bsl",
        "Logistic_reg_tfidf",
        "LinearSVC_tfidf",
        "GRU_mcl0",
        "GRU_mcl1",
        "GRU_mcl2",
    ]

    # Lineplot des performance
    data_mcl = df_perf_mcl[metrics]
    data_mcl = data_mcl[data_mcl["model"].isin(models_list)].set_index("model")
    fig = px.line(
        data_mcl.T, markers=True, title="M√©triques pour une s√©lection de mod√®les"
    )
    fig.update_yaxes(tick0=0, dtick=0.1)
    fig.add_hline(y=0.5, line_dash="dash", line_color="red")
    st.plotly_chart(fig, use_container_width=True)

    # Affichage au choix des matrices de confusion
    st.markdown("Afficher la matrice de confusion d'un mod√®le de votre choix:")
    # [TO DO TO DO ----------]
    # [TO DO TO DO ----------]

    st.write("### Pr√©dictions")
    # Exemples de commentaires dont on veut pr√©dire le sentiment :
    comment_1 = """Je suis tr√®s satisfait de mon achat. La livraison est rapide. 
                   Je recommande vivement la redoute."""
    comment_2 = """Je suis tr√®s d√©√ßus du produit re√ßu. Le colis √©tait abim√© et la livraison avait beaucoup de retard. 
                    Impossible de joindre le service client."""
    comment_3 = "J'ai re√ßu mon produit sans plus. rien √† signaler"

    # chargement d'un mod√®le de r√©seau de neuronnes
    @st.cache_data
    def load_nn_model(model_name):
        model_saved = tf.keras.models.load_model(model_name)
        return model_saved

    # chargement d'un mod√®le sklearn
    @st.cache_data
    def load_pkl_model(model_file):
        return pickle.load(open(model_file, "rb"))

    model_gru = load_nn_model("gru_0_text_vect")
    model_tfidf = load_pkl_model("tfidf_grid_lreg.pkl")

    # options de choix du commentaire √† pr√©dire
    options = ["", comment_1, comment_2, comment_3]
    # menu de s√©lection du commentaire
    comment_selected = st.selectbox("##### S√©lectionnez un commentaire", options)
    if comment_selected == "":
        prediction_gru = ""
        prediction_tfidf = ""
    else:
        tos = np.array([comment_selected])
        # prediction du sentiment pour le commentaire s√©lectionn√©
        prediction_gru = 1 * (model_gru.predict([tos]) > 0.5)[:, 0]
        prediction_tfidf = model_tfidf.predict(tos)

    col1, col2 = st.columns(2)
    with col1:
        st.markdown("##### Pr√©diction GRU:")
        st.write(prediction_gru)
    with col2:
        st.markdown("##### Pr√©diction TFIDF - Regression Log.")
        st.write(prediction_tfidf)

if page == pages[4]:
    st.write("## Analyse de Sentiment")
    st.write(
        "Il est important -  avant de conduire ce type d‚Äôanalyse - **de pr√©parer le texte** afin qu‚Äôil soit le plus exploitable possible aux diff√©rents outils disponibles."
    )
    st.write(
        "On parle de pre-processing notamment en utilisant des techniques de **racinisation, tokenisation, utilisation d'expressions regulieres et suppression des stop words**."
    )

    # Titre
    st.header("R√©sum√© de l'Analyse de Sentiments")

    # Introduction
    st.write(
        "On constate √† travers nos diverses it√©rations que l‚Äôanalyse de texte peut s‚Äôav√©rer ardue et reste  un processus tr√®s it√©ratif. Il en ressort aussi que certains outils vont tr√®s bien identifier la neutralit√© d‚Äôun commentaire mais par contre ne vont pas supporter une bonne pr√©diction de note.."
    )

    # Approches non supervis√©es
    st.header("Approches non supervis√©es :")

    # Word Cloud
    st.subheader("Word Cloud :")
    st.write(
        "Cr√©ation de 'Word Cloud' √† partir des commentaires pour visualiser les th√®mes dominants.  Il s‚Äôagit d‚Äôun **outil tr√®s pratique**, qui combin√© √† d‚Äôautres techniques comme la vectorisation peut se r√©v√©ler int√©ressant."
    )

    # Sentiment Analysis
    st.subheader("Outils √† disposition :")
    st.write(
        "L'analyse de sentiments couvre diverses m√©thodes, de la simple utilisation de lexiques √† des approches avanc√©es avec transformers. Nous avons utilis√© des outils tels que **Word Cloud, Text Blob, Vader, Naive Bayes et Bert**. **Multinomial Naive Bayes** est un algorithme de classification bay√©sienne na√Øve qui est adapt√© pour des donn√©es cat√©gorielles discr√®tes. **BERT**(Bidirectional Encoder Representations from Transformers) est un mod√®le de traitement du langage naturel bas√© sur des transformers, qui sont des mod√®les de r√©seaux de neurones particuli√®rement performants dans le traitement s√©quentiel de donn√©es."
    )

    # Exemple avec Vader
    st.subheader("Prenons un exemple avec Vader :")
    st.write(
        "VADER utilise un lexique pr√©-√©tiquet√© qui prend en compte la polarit√©, l'intensit√© et les √©motions li√©es aux mots sp√©cialement con√ßu pour g√©rer les nuances du langage naturel."
    )

    # Chargement des donn√©es
    df = pd.read_csv("redoute_v3.csv")

    # T√©l√©chargement du lexique VADER pour l'analyse de sentiment
    nltk.download("vader_lexicon")

    # S√©lection d'un exemple de commentaire
    comment = st.text_area(
        "Exemple:",
        "je commande depuis longtemps chez la redoute; j'y appr√©cie le choix , la rapidit√© de livraison et la facilit√© de r√®glement gr√¢ce √† la carte ,m√™me si presque  √† chaque fois je demandais un r√®glement comptant cela m'√©vitait de laisser mon num√©ro de carte bleue  sur le web ...par contre depuis quelques jours cela a chang√© je n'y comprends plus rien je ne peux plus payer comme √ßa alors que  je n'ai absolument  aucun d√©bit  en attente sur mon compte ....du coup par s√©curit√© face √† l'internet  j'ai d√ª r√©gler  mes deux derni√®res commandes avec une carte bancaire √† usage unique ce qui est un peu  plus compliqu√© pour moi et risque  forcement de me faire h√©siter pour des   futurs  achats sur ce site....dommage.",
    )

    # Initialisation de l'analyseur de sentiment VADER
    sid = SentimentIntensityAnalyzer()

    # Calcul du score de sentiment
    sentiment_score = sid.polarity_scores(comment)

    # Vader result on this specific example
    x = [0.0, 0.977, 0.023, 0.4215]

    st.set_option("deprecation.showPyplotGlobalUse", False)
    plt.figure(figsize=(8, 6))
    plt.pie(x, labels=["negative", "neutral", "positive", "coumpound"])
    plt.title("Distribution of VADER Sentiment Scores")
    plt.legend()
    st.pyplot()

    st.write(
        " Le resultat pour cet example exprime plus de **97% de neutralit√©**, en effet la lecture du texte r√©v√®le une tonalit√© mixte avec des aspects positifs et des pr√©occupations."
    )

    # Affichage du score de sentiment
    # st.write("Score de sentiment :", sentiment_score)

    # BERT
    st.subheader("BERT:")
    st.write(
        "L'utilisation de BERT pr√©-entra√Æn√© pour l'analyse de sentiment est puissante car il peut comprendre le contexte et les relations entre les mots de mani√®re plus sophistiqu√©e que les m√©thodes traditionnelles. Les resultats sont plus proches du rating client que Vader, am√©liorant la pr√©cision de l'√©valuation du sentiment."
    )

    # st.write(' ## Nous avons utilis√© plusieurs librairies dites pr√©-entra√Æn√©es telles que Vader, TextBlob, Bert')
    # M√©canisme : Un texte ü°∫ un score de tonalit√© n√©gatif /positif
    # PieChart : Distribution du score de sentiments
    # Diagramme Barre => neutralit√© g√©n√©rale
    # Graphique : Neutralit√© des r√©ponses fournisseurs
    # Graphique : distribution rating versus Tonalit√©s sentiments


if page == pages[5]:
    st.write("## Topic Modeling")
    # objectifs : topics commentaires
    # D√©marche / LDA
    # R√©sultats
    st.write(
        """
    **Objectifs :** Dans le but de satisfaire notre client et de faciliter la cat√©gorisation des commentaires clients et des r√©ponses, nous avons explor√© le topic modeling avec le mod√®le Latent Dirichlet Allocation de la librairie Gensim en Python.

    **M√©thodologie :**
    - D√©finition d‚Äôun corpus de mots : nos commentaires nettoy√©s et tokenis√©s, rassembl√©s en bag of words.
    - Application du mod√®le LDA et cr√©ation d‚Äôun dictionnaire √©tablissant la correspondance entre les mots du corpus et les identifiants du mod√®le.

    **R√©sultats :** L‚Äôanalyse LDA nous a permis d'identifier les sujets dominants pour chaque commentaire, r√©v√©lant des th√®mes li√©s √† la vente par correspondance, tels que les probl√®mes de livraison, de paiement, de conformit√© de taille, etc.
    """
    )

    # Exemple de Sentiment Analysis Bert, combin√© au Topic modeling via un Chatbot

    df = pd.read_csv("redoute_v3.csv")
    # df = df.head(20)

    # word.isalpha() permet de filtrer que les caracteres, va enlever les chiffres, ponctuations et caracteres speciaux

    # Fonction pour nettoyer le texte
    def nettoyer_texte(comment):
        stop_words = set(stopwords.words("french"))
        ps = PorterStemmer()
        words = [
            ps.stem(word)
            for word in word_tokenize(comment.lower())
            if word.isalpha() and word not in stop_words
        ]
        return " ".join(words)

    # Cr√©er une nouvelle colonne 'comment_cleaned' en appliquant la fonction nettoyer_texte
    df["comment_cleaned"] = df["comment"].apply(nettoyer_texte)

    # nettoyage supplementaire avec une regex qui prend uniquement les mots de 4 caracteres

    def apply_regex(chaine):
        tokenizer = RegexpTokenizer("[a-zA-Z√©]{4,}")
        tokens_regex = tokenizer.tokenize(chaine)
        return " ".join(tokens_regex)  # pour rejoindre les tokens en une cha√Æne

    # Appliquation de la fonction √† la colonne 'comment_cleaned'
    df["comment_cleaned"] = df["comment_cleaned"].apply(apply_regex)

    # Charger le mod√®le de sentiment BERT
    # model = TFBertForSequenceClassification.from_pretrained("nlptown/bert-base-multilingual-uncased-sentiment")
    model = TFBertForSequenceClassification.from_pretrained(
        "/Users/dkcentral/Documents/500_fmt_ml_inge/01_DataScientist/99_pjt_fil_rouge/streamlit_fusion/Bert"
    )
    # tokenizer = BertTokenizer.from_pretrained("nlptown/bert-base-multilingual-uncased-sentiment")
    tokenizer = BertTokenizer.from_pretrained(
        "/Users/dkcentral/Documents/500_fmt_ml_inge/01_DataScientist/99_pjt_fil_rouge/streamlit_fusion/Bert"
    )

    # Appliquer l'analyse de sentiment BERT √† la colonne 'comment_cleaned'
    def predict_sentiment(comment):
        tokens = tokenizer.encode_plus(
            comment, return_tensors="tf", max_length=512, truncation=True
        )
        logits = model(tokens)["logits"]
        return np.argmax(logits.numpy())

    df["sentiment_bert"] = df["comment_cleaned"].apply(predict_sentiment)

    # Cr√©er le dictionnaire et le corpus bas√©s sur les commentaires nettoy√©s (bag of words)
    dictionary = corpora.Dictionary(df["comment_cleaned"].apply(word_tokenize))
    corpus = [
        dictionary.doc2bow(word_tokenize(comment)) for comment in df["comment_cleaned"]
    ]

    def topic_modeling(comment, corpus, dictionary, num_topics=5):
        lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)
        topics = lda_model.print_topics(num_words=3)
        return topics

    # Cr√©er le dictionnaire et le corpus bas√©s sur les commentaires nettoy√©s
    # dictionary = corpora.Dictionary(df['comment_cleaned'].apply(word_tokenize))
    # corpus = [dictionary.doc2bow(word_tokenize(comment)) for comment in df['comment_cleaned']]

    # Cr√©er le mod√®le LDA
    lda_model = models.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)

    # Obtenir les termes les plus fr√©quents pour chaque topic - ici j'ai choisi 4 topics via topn
    # on parcourt chaque topic du modele lda et on les stocke ds topic_terms
    topic_terms = {}
    for topic_id in range(lda_model.num_topics):
        terms = lda_model.show_topic(topic_id, topn=4)
        topic_terms[topic_id] = [term for term, _ in terms]

    def get_dominant_topic(comment, lda_model, dictionary):
        # Utiliser le mod√®le LDA pour obtenir la distribution des topics
        bow_vector = dictionary.doc2bow(word_tokenize(comment))
        topics_distribution = lda_model.get_document_topics(bow_vector)

        # Trouver le topic dominant (num√©ro de topic) avec la probabilite la plus elevee
        # rappel : topics_distribution:  chaque √©l√©ment est un tuple de la forme (topic_id, probability)
        dominant_topic = max(topics_distribution, key=lambda x: x[1])[0]

        return dominant_topic

    def get_topic_name(topic_id):
        # Obtenir les termes les plus fr√©quents du topic
        terms = topic_terms.get(topic_id, [])
        return ", ".join(terms)

    # Titre de l'application - chatbot
    st.subheader("Chatbot interactif avec Analyse de sentiment Bert et topic modeling")

    # Section pour choisir un commentaire
    selected_comment_index = st.number_input(
        "Saisissez l'index du commentaire :",
        min_value=0,
        max_value=len(df) - 1,
        value=0,
        step=1,
    )

    # Affichage du commentaire s√©lectionn√©
    selected_comment = df.loc[selected_comment_index, "comment"]
    st.subheader("Commentaire s√©lectionn√© :")
    st.write(selected_comment)

    # Analyse de sentiment avec BERT
    sentiment_label = predict_sentiment(selected_comment)
    st.subheader("Analyse de Sentiment BERT :")
    st.write(f"Sentiment : {sentiment_label}")
    st.write(
        "Pour rappel, l'√©chelle Bert du mod√®le choisi va de 0 a 4. 0 √©tant tr√®s n√©gatif et 4 tr√®s positif"
    )

    # Topic Modeling
    dominant_topic = get_dominant_topic(selected_comment, lda_model, dictionary)
    topic_name = get_topic_name(dominant_topic)
    st.subheader("Topic Modeling :")
    st.write(f"Topics dominants : {topic_name}")

    # Rating client
    rating = df.loc[selected_comment_index, "rating"]
    st.subheader("Rating client :")
    st.write(f"Rating client: {rating}")

    print("---")


if page == pages[6]:
    st.write("## Pr√©diction de la R√©ponse Fournisseur")
    # objectifs
    # D√©marche
    # R√©sultats

if page == pages[7]:
    st.write("## D√©mo")
    # commentaires pos, neg, ambigu
    # pr√©diction du rating
    # pr√©diction du sentiment
    # pr√©diction du topic
    # pr√©diction r√©ponse fournisseur

if page == pages[8]:
    st.write("## Conclusion & Perspectives")
    # Conclusions
    # Perspectives
    # Introduction
    st.markdown(
        "Notre projet visait √† pr√©dire les notations des clients, cat√©goriser les commentaires, proposer des r√©ponses automatiques, et analyser les sentiments."
    )

    # Approche 1 : Mod√®les de classification
    st.subheader("Mod√®les de classification")
    st.markdown(
        "L‚Äôutilisation de divers mod√®les pour pr√©dire le sentiment client en se basant sur la longueur du commentaire, du titre, et la dur√©e depuis la transaction. **La r√©gression logistique simple a montr√© des performances notables**."
    )

    # Approche 2 : Bag of Words avec TF IDF et Count Vectorizer
    st.subheader("Bag of Words avec TF IDF et Count Vectorizer")
    st.markdown(
        "L'application du **Bag of Words avec TF IDF et Count Vectorizer** a permis **une bonne pr√©cision d‚Äôensemble**. Cependant, des limitations subsistent dans la pr√©cision de pr√©diction du sentiment n√©gatif."
    )

    # Approche 3 : R√©seaux de Neurones R√©currents GRU
    st.subheader("R√©seaux de Neurones R√©currents GRU")
    st.markdown(
        "**Les GRU ont surpass√© les mod√®les pr√©c√©dents, atteignant des pr√©cisions globales d√©passant 91%**, am√©liorant nettement la pr√©cision dans la pr√©diction du sentiment n√©gatif. Le r√©√©chantillonnage et la prise en compte du poids des classes pour les r√©seaux de neurones ont √©t√© essentiels pour √©quilibrer les donn√©es quel que soit le mod√®le."
    )

    # Pr√©diction du retour fournisseur
    st.subheader("Pr√©diction du retour fournisseur")
    st.markdown(
        "Une approche parall√®le a √©t√© adopt√©e, mettant l'accent sur le feature engineering, la recherche d'une trame standard, et le fine-tuning des mod√®les. L'analyse des commentaires fournisseur a r√©v√©l√© des **tendances sp√©cifiques** telles qu‚Äôune **standardisation des r√©ponses**, confirmant nos hypoth√®ses."
    )

    # Analyse des sentiments
    st.subheader("Analyse des sentiments")
    st.markdown(
        "Des word clouds √† BERT, les approches supervis√©es et semi-supervis√©es, notamment Bert et le Topic Modeling, ont fourni des informations tres tangibles."
    )

    # Chatbot interactif
    st.subheader("Chatbot interactif")
    st.markdown(
        "La mise en place d'un **Chatbot interactif**, int√©grant une √©valuation des sentiments et pr√©sentant les quatre principaux sujets sous-jacents, a rendu **conviviale l'analyse des commentaires**. Les r√©sultats concluants mettent en lumi√®re l'utilit√© de cet outil."
    )

    # Conclusion
    st.subheader("Conclusion")
    st.markdown(
        "En r√©sum√©, nos analyses approfondies nous ont permis d‚Äô√©laborer un bon syst√®me de pr√©dictions de l'√©valuation des commentaires, mais comme dans tout mod√®le de pr√©diction, des efforts continus sont n√©cessaires pour le perfectionner et optimiser les param√®tres. √Ä un stade avanc√©, une mod√©lisation de sujets plus pr√©cis pourrait diriger les commentaires vers les d√©partements sp√©cifiquement concern√©s."
    )
