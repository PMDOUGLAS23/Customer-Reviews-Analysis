import streamlit as st
import pandas as pd
import io

df = pd.read_csv("redoute.csv", sep=";")

# Titre principal
st.title(":blue[Customers Reviews Analytics]")

# Barre lat√©rale avec le sommaire
st.sidebar.title(":blue[Sommaire]")
pages = [
    "Introduction",
    "Collecte des Donn√©es",
    "Exploration et Analyse des Donn√©es",
    "Pr√©diction du Rating",
    "Analyse de Sentiment",
    "Topic Modeling",
    "Pr√©diction de la R√©ponse Fournisseur",
    "D√©mo",
    "Conclusion et Perspectives",
]

# S√©lection de la page dans la barre lat√©rale
page = st.sidebar.radio("Aller vers", pages)

# Contenu de chaque page
if page == pages[0]:
    st.write("## Introduction")
    st.write("#### Objectifs du Projet")
    st.markdown("- Pr√©dire les notations des clients")
    st.markdown("- Cat√©goriser les commentaires")
    st.markdown("- Proposer des r√©ponses automatiques")
    st.markdown("- Analyser les sentiments")

    st.write("#### Equipe Projet")
    st.text(
        """
        xxx
        xxx
        xxx
        """
    )

if page == pages[1]:
    # Source de donn√©es
    col1, col2 = st.columns(2)
    with col1:
        st.write("##### Source de donn√©es")
    with col2:
        st.markdown(
            """ **TrustedShops**, Entreprise allemande qui propose entre autres:
                        Certification de sites web marchands
                        Services **d'√©valuation et d'avis clients**
                    """,
            unsafe_allow_html=True,
        )

    # Entreprise cible
    col3, col4 = st.columns(2)
    with col3:
        st.markdown("##### Entreprise cibl√©e")
    with col4:
        st.markdown(
            "**La Redoute**, Leader fran√ßais du e-commerce en mode et maison",
            unsafe_allow_html=True,
        )
    col5, col6 = st.columns(2)
    with col5:
        st.markdown(
            "##### Collecte des donn√©es des avis clients", unsafe_allow_html=True
        )
    with col6:
        st.markdown(
            "Etape 1 : **request.get + BeautifulSoup + Pandas**", unsafe_allow_html=True
        )
        st.markdown(
            "√âtape 2: 1er nettoyage et formatage des donn√©es, puis stockage dans un fichier .csv",
            unsafe_allow_html=True,
        )

    st.markdown("##### Donn√©es pour l'Analyse Exploratoire", unsafe_allow_html=True)
    st.dataframe(df.head(5))
    # pour afficher df.info()
    buffer = io.StringIO()
    df.info(buf=buffer)
    s = buffer.getvalue()
    st.text(s)


if page == pages[2]:
    st.write("## Exploration et Analyse des Donn√©es")
    st.markdown("- xx")
    st.markdown("- xx")
    st.markdown("- xx")

if page == pages[3]:
    st.write("## Pr√©diction du Rating en Fonction des Commentaires")
    st.write("#### Probl√©matique")
    # poser la probl√©matique

    st.write("#### D√©marche")
    # Mod√©lisation de base avec 3 variables explicatives
    # Bag of Words
    # GRU
    st.write("#### Mod√©lisation de Base")
    # Mod√©lisation de base avec 3 variables explicatives

    st.write("#### Bag of Words")
    # BoW , Tfidf , Cvtz ...

    st.write("#### GRU")
    # BoW , Tfidf , Cvtz ...

    st.write("#### R√©sultats")

if page == pages[4]:
    st.write("## Analyse de Sentiment")
    # Librairies pr√©-entra√Æn√©es : Vader, TextBlob, Bert
    # M√©canisme : Un texte ü°∫ un score de tonalit√© n√©gatif /positif
    # PieChart : Distribution du score de sentiments
    # Diagramme Barre => neutralit√© g√©n√©rale
    # Graphique : Neutralit√© des r√©ponses fournisseurs
    # Graphique : distribution rating versus Tonalit√©s sentiments

if page == pages[5]:
    st.write("## Topic Modeling")
    # objectifs : topics commentaires
    # D√©marche / LDA
    # R√©sultats

if page == pages[6]:
    st.write("## Pr√©diction de la R√©ponse Fournisseur")
    # objectifs
    # D√©marche
    # R√©sultats

if page == pages[7]:
    st.write("## D√©mo")
    # commentaires pos, neg, ambigu
    # pr√©diction du rating
    # pr√©diction du sentiment
    # pr√©diction du topic
    # pr√©diction r√©ponse fournisseur

if page == pages[8]:
    st.write("## Conclusion & Perspectives")
    # Conclusions
    # Perspectives
